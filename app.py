import streamlit as st
from dotenv import load_dotenv
import os
import time
from supabase import create_client, Client
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
# --- Thay Ä‘á»•i 1: Import cÃ¡c lá»›p tá»« Google ---
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.chains import ConversationalRetrievalChain
from langchain_community.vectorstores import SupabaseVectorStore
from langchain.memory import ConversationBufferMemory
import google.generativeai as genai # ThÃªm import nÃ y
from langchain.prompts import PromptTemplate


# ===== STREAMLIT PAGE CONFIG =====
st.set_page_config(
    page_title="ğŸ¤– AI Trá»£ Giáº£ng ToÃ¡n Tin",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/yourusername/chatbot',
        'Report a bug': "https://github.com/yourusername/chatbot/issues",
        'About': "# AI Trá»£ Giáº£ng ToÃ¡n Tin\nPowered by Gemini & Supabase"
    }
)

# ===== CUSTOM CSS STYLING =====
st.markdown("""
<style>
/* Import Google Fonts */
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

/* Global Styling */
.stApp {
    font-family: 'Inter', sans-serif;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
}

/* Main Container */
.main .block-container {
    padding-top: 2rem;
    padding-bottom: 2rem;
    max-width: 1200px;
}

/* Header Styling */
.main-header {
    text-align: center;
    padding: 2rem 0;
    background: rgba(255, 255, 255, 0.1);
    border-radius: 20px;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255, 255, 255, 0.2);
    margin-bottom: 2rem;
    box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
}

.main-title {
    font-size: 3rem;
    font-weight: 700;
    background: linear-gradient(45deg, #FF6B6B, #4ECDC4, #45B7D1, #96CEB4);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    margin-bottom: 0.5rem;
    animation: gradient 3s ease-in-out infinite;
}

.main-subtitle {
    font-size: 1.2rem;
    color: rgba(255, 255, 255, 0.8);
    font-weight: 400;
}

@keyframes gradient {
    0%, 100% { background-position: 0% 50%; }
    50% { background-position: 100% 50%; }
}

/* Sidebar Styling */
.css-1d391kg {
    background: linear-gradient(180deg, #2C3E50 0%, #34495E 100%);
}

.sidebar-header {
    background: linear-gradient(135deg, #FF6B6B, #4ECDC4);
    padding: 1.5rem;
    border-radius: 15px;
    margin-bottom: 1.5rem;
    text-align: center;
    color: white;
    font-weight: 600;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
}

/* File Uploader Styling */
.stFileUploader {
    background: rgba(255, 255, 255, 0.1);
    border-radius: 15px;
    padding: 1rem;
    border: 2px dashed rgba(255, 255, 255, 0.3);
    transition: all 0.3s ease;
}

.stFileUploader:hover {
    border-color: #4ECDC4;
    background: rgba(78, 205, 196, 0.1);
    transform: translateY(-2px);
}

/* Button Styling */
.stButton > button {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border: none;
    border-radius: 25px;
    padding: 0.75rem 2rem;
    font-weight: 600;
    font-size: 1rem;
    transition: all 0.3s ease;
    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
    width: 100%;
}

.stButton > button:hover {
    transform: translateY(-3px);
    box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
    background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
}

/* Chat Messages */
.stChatMessage {
    background: rgba(255, 255, 255, 0.1);
    border-radius: 15px;
    padding: 1rem;
    margin: 0.5rem 0;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255, 255, 255, 0.2);
    animation: fadeIn 0.5s ease-in;
}

@keyframes fadeIn {
    from { opacity: 0; transform: translateY(10px); }
    to { opacity: 1; transform: translateY(0); }
}

/* User Message */
.stChatMessage[data-testid="user-message"] {
    background: linear-gradient(135deg, #FF6B6B, #FF8E53);
    margin-left: 20%;
}

/* Assistant Message */
.stChatMessage[data-testid="assistant-message"] {
    background: linear-gradient(135deg, #4ECDC4, #44A08D);
    margin-right: 20%;
}

/* Chat Input */
.stChatInput > div > div > input {
    background: rgba(255, 255, 255, 0.1);
    border: 2px solid rgba(255, 255, 255, 0.3);
    border-radius: 25px;
    color: white;
    font-size: 1rem;
    padding: 1rem 1.5rem;
    backdrop-filter: blur(10px);
}

.stChatInput > div > div > input:focus {
    border-color: #4ECDC4;
    box-shadow: 0 0 20px rgba(78, 205, 196, 0.3);
}

/* Success/Error Messages */
.stSuccess {
    background: linear-gradient(135deg, #56ab2f, #a8e6cf);
    border-radius: 15px;
    border: none;
    color: white;
    font-weight: 500;
}

.stError {
    background: linear-gradient(135deg, #ff416c, #ff4b2b);
    border-radius: 15px;
    border: none;
    color: white;
    font-weight: 500;
}

/* Spinner */
.stSpinner {
    text-align: center;
}

/* Stats Cards */
.stats-card {
    background: rgba(255, 255, 255, 0.1);
    padding: 1.5rem;
    border-radius: 15px;
    text-align: center;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255, 255, 255, 0.2);
    margin: 0.5rem;
    transition: transform 0.3s ease;
}

.stats-card:hover {
    transform: translateY(-5px);
}

.stats-number {
    font-size: 2rem;
    font-weight: 700;
    color: #4ECDC4;
}

.stats-label {
    font-size: 0.9rem;
    color: rgba(255, 255, 255, 0.7);
    margin-top: 0.5rem;
}

/* Responsive Design */
@media (max-width: 768px) {
    .main-title {
        font-size: 2rem;
    }
    
    .stChatMessage[data-testid="user-message"] {
        margin-left: 10%;
    }
    
    .stChatMessage[data-testid="assistant-message"] {
        margin-right: 10%;
    }
}
</style>
""", unsafe_allow_html=True)

# Táº£i cÃ¡c biáº¿n mÃ´i trÆ°á»ng tá»« file .env
load_dotenv()

def stream_parser(stream):
    """
    Láº¯ng nghe má»™t stream tá»« LangChain vÃ  chá»‰ yield (Ä‘áº©y ra) pháº§n ná»™i dung cá»§a "answer".
    """
    for chunk in stream:
        if "answer" in chunk:
            yield chunk["answer"]

# --- Thay Ä‘á»•i 2: Láº¥y Google API Key vÃ  cáº¥u hÃ¬nh ---
try:
    google_api_key = os.getenv("GOOGLE_API_KEY")
    if not google_api_key:
        st.error("Vui lÃ²ng thiáº¿t láº­p biáº¿n mÃ´i trÆ°á»ng GOOGLE_API_KEY trong file .env")
        st.stop()
    genai.configure(api_key=google_api_key) # Cáº¥u hÃ¬nh API key cho thÆ° viá»‡n Google

    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_KEY")
    if not all([supabase_url, supabase_key]):
        st.error("Vui lÃ²ng thiáº¿t láº­p cÃ¡c biáº¿n mÃ´i trÆ°á»ng SUPABASE_URL, vÃ  SUPABASE_KEY trong file .env")
        st.stop()

    supabase: Client = create_client(supabase_url, supabase_key)

    # --- Thay Ä‘á»•i 3: Khá»Ÿi táº¡o Google Embeddings ---
    # Sá»­ dá»¥ng mÃ´ hÃ¬nh embedding cá»§a Google
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    
    vector_store = SupabaseVectorStore(client=supabase, table_name="documents", embedding=embeddings, query_name = "match_documents")
    
    # --- Thay Ä‘á»•i 4: Khá»Ÿi táº¡o mÃ´ hÃ¬nh Chat Gemini ---
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-pro", temperature=0.3, convert_system_message_to_human=True)
    
    # Thiáº¿t láº­p prompt
    prompt_template = ("""
                       Báº¡n lÃ  má»™t trá»£ giáº£ng AI chuyÃªn ngÃ nh ToÃ¡n Tin, thÃ¢n thiá»‡n vÃ  cá»±c ká»³ cáº©n tháº­n. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  giÃºp sinh viÃªn hiá»ƒu sÃ¢u cÃ¡c khÃ¡i niá»‡m, giáº£i bÃ i táº­p vÃ  Ã´n táº­p dá»±a trÃªn tÃ i liá»‡u há»c táº­p cá»§a há».

                       QUY Táº®C VÃ€NG: CÃ¢u tráº£ lá»i cá»§a báº¡n Báº®T BUá»˜C pháº£i dá»±a HOÃ€N TOÃ€N vÃ o Ná»˜I DUNG cá»§a "Ngá»¯ cáº£nh tÃ i liá»‡u" Ä‘Æ°á»£c cung cáº¥p dÆ°á»›i Ä‘Ã¢y. KhÃ´ng Ä‘Æ°á»£c bá»‹a Ä‘áº·t hay sá»­ dá»¥ng kiáº¿n thá»©c bÃªn ngoÃ i tÃ i liá»‡u.

                       QUY TRÃŒNH TRáº¢ Lá»œI:
                       1. Äá»c ká»¹ "CÃ¢u há»i" vÃ  "Ngá»¯ cáº£nh tÃ i liá»‡u".
                        2. Náº¿u cÃ¢u há»i cÃ³ thá»ƒ Ä‘Æ°á»£c tráº£ lá»i tá»« ngá»¯ cáº£nh, hÃ£y tráº£ lá»i má»™t cÃ¡ch rÃµ rÃ ng vÃ  Ä‘i tháº³ng vÃ o váº¥n Ä‘á».
                        - Khi giáº£i thÃ­ch cÃ¡c Ä‘á»‹nh nghÄ©a, thuáº­t toÃ¡n hoáº·c Ä‘á»‹nh lÃ½ (vÃ­ dá»¥: 'Äá»“ thá»‹ Euler', 'Thuáº­t toÃ¡n Dijkstra'), hÃ£y cá»‘ gáº¯ng trÃ¬nh bÃ y theo cáº¥u trÃºc: Äá»‹nh nghÄ©a -> TÃ­nh cháº¥t/CÃ¡c bÆ°á»›c -> VÃ­ dá»¥ (náº¿u cÃ³ trong tÃ i liá»‡u).
                        - Sá»­ dá»¥ng Markdown Ä‘á»ƒ Ä‘á»‹nh dáº¡ng cÃ¢u tráº£ lá»i cho dá»… Ä‘á»c: **in Ä‘áº­m** cÃ¡c thuáº­t ngá»¯ quan trá»ng, dÃ¹ng danh sÃ¡ch (list) cho cÃ¡c bÆ°á»›c hoáº·c tÃ­nh cháº¥t.
                        3. Náº¿u cÃ¢u há»i khÃ´ng thá»ƒ Ä‘Æ°á»£c tráº£ lá»i tá»« ngá»¯ cáº£nh, hÃ£y tráº£ lá»i má»™t cÃ¡ch lá»‹ch sá»± ráº±ng: "TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» chá»§ Ä‘á» nÃ y trong cÃ¡c tÃ i liá»‡u báº¡n Ä‘Ã£ cung cáº¥p."
                        4. CÃ¢u tráº£ lá»i cáº§n cÃ³ Ä‘á»‹nh dáº¡ng Ä‘áº¹p, dá»… nhÃ¬n, markdown.
                        ---
                        Ngá»¯ cáº£nh tÃ i liá»‡u:
                        {context}
                        ---

                        CÃ¢u há»i: {question}

                        CÃ¢u tráº£ lá»i cá»§a Trá»£ giáº£ng AI: """)
    
    QA_prompt = PromptTemplate.from_template(prompt_template)
                        
    # Thiáº¿t láº­p bá»™ nhá»› Ä‘á»ƒ lÆ°u trá»¯ lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

    # Táº¡o chuá»—i xá»­ lÃ½ há»™i thoáº¡i
    qa = ConversationalRetrievalChain.from_llm(llm, retriever=vector_store.as_retriever(), memory=memory, combine_docs_chain_kwargs={"prompt": QA_prompt})

except Exception as e:
    st.error(f"Lá»—i khá»Ÿi táº¡o: {e}")
    st.stop()


def process_document(uploaded_file):
    """
    HÃ m xá»­ lÃ½ file Ä‘Æ°á»£c táº£i lÃªn: Ä‘á»c, cáº¯t nhá» vÃ  lÆ°u embeddings vÃ o Supabase.
    """
    try:
        # Táº¡o thÆ° má»¥c temp náº¿u chÆ°a cÃ³
        temp_dir = "./temp_files"
        os.makedirs(temp_dir, exist_ok=True)
        
        temp_file_path = os.path.join(temp_dir, uploaded_file.name)
        
        with open(temp_file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        if uploaded_file.type == "application/pdf":
            loader = PyPDFLoader(temp_file_path)
        elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            loader = Docx2txtLoader(temp_file_path)
        else:
            loader = TextLoader(temp_file_path)
        
        documents = loader.load()
        for doc in documents:
            doc.page_content = doc.page_content.replace('\u0000', '')

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        docs = text_splitter.split_documents(documents)
        
        vector_store.add_documents(docs)

        os.remove(temp_file_path)
        return True
    except Exception as e:
        st.error(f"Lá»—i khi xá»­ lÃ½ tÃ i liá»‡u: {e}")
        return False

# ===== HELPER FUNCTIONS =====
def display_typing_animation():
    """Hiá»ƒn thá»‹ animation typing vá»›i emoji"""
    typing_placeholder = st.empty()
    for i in range(3):
        typing_placeholder.markdown(f"ğŸ¤– **Trá»£ lÃ½ AI Ä‘ang suy nghÄ©{'.' * (i + 1)}**")
        time.sleep(0.5)
    typing_placeholder.empty()

def get_file_stats():
    """Láº¥y thá»‘ng kÃª file Ä‘Ã£ upload"""
    if "uploaded_files_count" not in st.session_state:
        st.session_state.uploaded_files_count = 0
    if "total_messages" not in st.session_state:
        st.session_state.total_messages = len(st.session_state.get("messages", []))
    return st.session_state.uploaded_files_count, st.session_state.total_messages

# ===== MAIN INTERFACE =====

# Beautiful Header with Animation
st.markdown("""
<div class="main-header">
    <h1 class="main-title">ğŸ§  AI Trá»£ Giáº£ng ToÃ¡n Tin</h1>
    <p class="main-subtitle">âœ¨ Powered by Gemini 2.5 Pro & Supabase Vector Store âœ¨</p>
    <div style="margin-top: 1rem;">
        <span style="background: rgba(255,255,255,0.2); padding: 0.5rem 1rem; border-radius: 20px; margin: 0 0.5rem; font-size: 0.9rem;">ğŸ“š Há»i Ä‘Ã¡p thÃ´ng minh</span>
        <span style="background: rgba(255,255,255,0.2); padding: 0.5rem 1rem; border-radius: 20px; margin: 0 0.5rem; font-size: 0.9rem;">ğŸš€ Streaming Response</span>
        <span style="background: rgba(255,255,255,0.2); padding: 0.5rem 1rem; border-radius: 20px; margin: 0 0.5rem; font-size: 0.9rem;">ğŸ¯ Context-Aware</span>
    </div>
</div>
""", unsafe_allow_html=True)

# Stats Dashboard
file_count, message_count = get_file_stats()
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.markdown(f"""
    <div class="stats-card">
        <div class="stats-number">{file_count}</div>
        <div class="stats-label">ğŸ“„ TÃ i liá»‡u</div>
    </div>
    """, unsafe_allow_html=True)

with col2:
    st.markdown(f"""
    <div class="stats-card">
        <div class="stats-number">{message_count}</div>
        <div class="stats-label">ğŸ’¬ Tin nháº¯n</div>
    </div>
    """, unsafe_allow_html=True)

with col3:
    st.markdown("""
    <div class="stats-card">
        <div class="stats-number">ğŸ”¥</div>
        <div class="stats-label">âš¡ Gemini 2.5</div>
    </div>
    """, unsafe_allow_html=True)

with col4:
    st.markdown("""
    <div class="stats-card">
        <div class="stats-number">âœ¨</div>
        <div class="stats-label">ğŸ¨ Modern UI</div>
    </div>
    """, unsafe_allow_html=True)

# ===== ENHANCED SIDEBAR =====
with st.sidebar:
    # Sidebar Header
    st.markdown("""
    <div class="sidebar-header">
        <h2 style="margin: 0; font-size: 1.5rem;">ğŸ“š Quáº£n lÃ½ TÃ i liá»‡u</h2>
        <p style="margin: 0.5rem 0 0 0; opacity: 0.9;">Upload & xá»­ lÃ½ tÃ i liá»‡u há»c táº­p</p>
    </div>
    """, unsafe_allow_html=True)
    
    # File Upload Section
    st.markdown("### ğŸ“ Táº£i lÃªn tÃ i liá»‡u")
    uploaded_files = st.file_uploader(
        "KÃ©o tháº£ hoáº·c chá»n file",
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True,
        help="Há»— trá»£: PDF, DOCX, TXT. CÃ³ thá»ƒ chá»n nhiá»u file cÃ¹ng lÃºc."
    )
    
    if uploaded_files:
        st.markdown(f"**ğŸ“Š ÄÃ£ chá»n {len(uploaded_files)} file:**")
        for file in uploaded_files:
            file_size = len(file.getvalue()) / 1024  # KB
            st.markdown(f"â€¢ `{file.name}` ({file_size:.1f} KB)")
        
        st.markdown("---")
        
        if st.button("ğŸš€ Xá»­ lÃ½ vÃ  Náº¡p kiáº¿n thá»©c", use_container_width=True):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, file in enumerate(uploaded_files):
                status_text.text(f"Äang xá»­ lÃ½: {file.name}")
                progress_bar.progress((i + 1) / len(uploaded_files))
                
                success = process_document(file)
                if success:
                    st.session_state.uploaded_files_count += 1
                    
            progress_bar.empty()
            status_text.empty()
            st.success(f"âœ… ÄÃ£ xá»­ lÃ½ thÃ nh cÃ´ng {len(uploaded_files)} tÃ i liá»‡u!")
            st.balloons()
    
    # Divider
    st.markdown("---")
    
    # Quick Actions
    st.markdown("### âš¡ Thao tÃ¡c nhanh")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ—‘ï¸ XÃ³a chat", use_container_width=True):
            st.session_state.messages = []
            st.rerun()
    
    with col2:
        if st.button("ğŸ”„ Reset", use_container_width=True):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()
    
    # Tips Section
    st.markdown("---")
    st.markdown("### ğŸ’¡ Máº¹o sá»­ dá»¥ng")
    st.markdown("""
    â€¢ ğŸ“ **Há»i cá»¥ thá»ƒ**: "Giáº£i thÃ­ch thuáº­t toÃ¡n Dijkstra"
    â€¢ ğŸ” **TÃ¬m kiáº¿m**: "TÃ¬m Ä‘á»‹nh nghÄ©a vá» Ä‘á»“ thá»‹"
    â€¢ ğŸ“Š **So sÃ¡nh**: "So sÃ¡nh BFS vÃ  DFS"
    â€¢ ğŸ§® **BÃ i táº­p**: "Cho vÃ­ dá»¥ vá» cÃ¢y nhá»‹ phÃ¢n"
    """)
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; opacity: 0.7; font-size: 0.8rem;">
        <p>ğŸ¤– Made with â¤ï¸ by Duy</p>
        <p>Powered by Streamlit & Gemini</p>
    </div>
    """, unsafe_allow_html=True)

# ===== ENHANCED CHAT INTERFACE =====

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# Welcome message for first time users
if not st.session_state.messages:
    st.markdown("""
    <div style="text-align: center; padding: 2rem; background: rgba(255,255,255,0.1); border-radius: 15px; margin: 2rem 0; backdrop-filter: blur(10px);">
        <h3 style="color: #4ECDC4; margin-bottom: 1rem;">ğŸ‘‹ ChÃ o má»«ng Ä‘áº¿n vá»›i AI Trá»£ Giáº£ng!</h3>
        <p style="color: rgba(255,255,255,0.8); margin-bottom: 1rem;">TÃ´i lÃ  trá»£ lÃ½ AI chuyÃªn ngÃ nh ToÃ¡n Tin, sáºµn sÃ ng giÃºp báº¡n:</p>
        <div style="display: flex; justify-content: center; flex-wrap: wrap; gap: 1rem; margin-top: 1rem;">
            <span style="background: rgba(255,107,107,0.2); color: #FF6B6B; padding: 0.5rem 1rem; border-radius: 20px; font-size: 0.9rem;">ğŸ§® Giáº£i bÃ i táº­p</span>
            <span style="background: rgba(78,205,196,0.2); color: #4ECDC4; padding: 0.5rem 1rem; border-radius: 20px; font-size: 0.9rem;">ğŸ“š Giáº£i thÃ­ch lÃ½ thuyáº¿t</span>
            <span style="background: rgba(69,183,209,0.2); color: #45B7D1; padding: 0.5rem 1rem; border-radius: 20px; font-size: 0.9rem;">ğŸ” TÃ¬m kiáº¿m thÃ´ng tin</span>
        </div>
        <p style="color: rgba(255,255,255,0.6); font-size: 0.9rem; margin-top: 1rem;">ğŸ’¡ HÃ£y upload tÃ i liá»‡u vÃ  báº¯t Ä‘áº§u há»i Ä‘Ã¡p!</p>
    </div>
    """, unsafe_allow_html=True)

# Display chat messages with enhanced styling
for i, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"], avatar="ğŸ‘¤" if message["role"] == "user" else "ğŸ¤–"):
        if message["role"] == "user":
            st.markdown(f"**Báº¡n:** {message['content']}")
        else:
            st.markdown(message["content"])

# Enhanced chat input with suggestions
if prompt := st.chat_input("ğŸ’¬ HÃ£y Ä‘áº·t cÃ¢u há»i vá» tÃ i liá»‡u cá»§a báº¡n...", key="chat_input"):
    # Add user message to history
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.total_messages = len(st.session_state.messages)
    
    # Display user message
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(f"**Báº¡n:** {prompt}")

    # Display assistant response with enhanced streaming
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        # Show typing indicator
        thinking_placeholder = st.empty()
        thinking_placeholder.markdown("ğŸ¤– **Äang phÃ¢n tÃ­ch tÃ i liá»‡u vÃ  táº¡o cÃ¢u tráº£ lá»i...** â³")
        
        try:
            # Stream the response
            raw_stream = qa.stream(prompt)
            thinking_placeholder.empty()
            
            # Display streaming response with better formatting
            full_response = st.write_stream(stream_parser(raw_stream))
            
            # Add reaction buttons
            col1, col2, col3, col4 = st.columns([1, 1, 1, 6])
            with col1:
                if st.button("ğŸ‘", key=f"like_{len(st.session_state.messages)}"):
                    st.toast("Cáº£m Æ¡n pháº£n há»“i cá»§a báº¡n! ğŸ˜Š", icon="ğŸ‘")
            with col2:
                if st.button("ğŸ‘", key=f"dislike_{len(st.session_state.messages)}"):
                    st.toast("TÃ´i sáº½ cá»‘ gáº¯ng cáº£i thiá»‡n! ğŸ™", icon="ğŸ‘")
            with col3:
                if st.button("ğŸ”„", key=f"retry_{len(st.session_state.messages)}"):
                    st.rerun()
                    
        except Exception as e:
            thinking_placeholder.empty()
            st.error(f"âŒ CÃ³ lá»—i xáº£y ra: {str(e)}")
            full_response = "Xin lá»—i, tÃ´i gáº·p sá»± cá»‘ khi xá»­ lÃ½ cÃ¢u há»i cá»§a báº¡n. Vui lÃ²ng thá»­ láº¡i."
        
    # Add response to history
    st.session_state.messages.append({"role": "assistant", "content": full_response})
    st.session_state.total_messages = len(st.session_state.messages)

# Quick question suggestions
if not st.session_state.messages or len(st.session_state.messages) < 2:
    st.markdown("### ğŸ’¡ CÃ¢u há»i gá»£i Ã½:")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ” TÃ¬m Ä‘á»‹nh nghÄ©a cÆ¡ báº£n", use_container_width=True):
            st.session_state.suggested_question = "HÃ£y giáº£i thÃ­ch cÃ¡c Ä‘á»‹nh nghÄ©a cÆ¡ báº£n trong tÃ i liá»‡u"
            st.rerun()
            
        if st.button("ğŸ“Š So sÃ¡nh cÃ¡c khÃ¡i niá»‡m", use_container_width=True):
            st.session_state.suggested_question = "So sÃ¡nh cÃ¡c khÃ¡i niá»‡m chÃ­nh trong tÃ i liá»‡u"
            st.rerun()
    
    with col2:
        if st.button("ğŸ§® Giáº£i thÃ­ch thuáº­t toÃ¡n", use_container_width=True):
            st.session_state.suggested_question = "Giáº£i thÃ­ch cÃ¡c thuáº­t toÃ¡n Ä‘Æ°á»£c Ä‘á» cáº­p trong tÃ i liá»‡u"
            st.rerun()
            
        if st.button("ğŸ“ TÃ³m táº¯t ná»™i dung", use_container_width=True):
            st.session_state.suggested_question = "TÃ³m táº¯t nhá»¯ng Ä‘iá»ƒm chÃ­nh trong tÃ i liá»‡u"
            st.rerun()
