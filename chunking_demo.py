"""
Demo script Ä‘á»ƒ test vÃ  so sÃ¡nh cÃ¡c chiáº¿n lÆ°á»£c Semantic Chunking
"""

import streamlit as st
from semantic_chunking import ChunkingManager
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.schema import Document
import time
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

def create_sample_documents():
    """Táº¡o cÃ¡c tÃ i liá»‡u máº«u Ä‘á»ƒ test"""
    
    # TÃ i liá»‡u toÃ¡n há»c
    math_content = """
    Äá»‹nh lÃ½ 1: Äá»‹nh lÃ½ Pythagoras
    Trong má»™t tam giÃ¡c vuÃ´ng, bÃ¬nh phÆ°Æ¡ng cáº¡nh huyá»n báº±ng tá»•ng bÃ¬nh phÆ°Æ¡ng hai cáº¡nh gÃ³c vuÃ´ng.
    CÃ´ng thá»©c: aÂ² + bÂ² = cÂ²
    
    Chá»©ng minh:
    XÃ©t tam giÃ¡c ABC vuÃ´ng táº¡i A, vá»›i BC lÃ  cáº¡nh huyá»n.
    Váº½ Ä‘Æ°á»ng cao AH tá»« A xuá»‘ng BC.
    Ta cÃ³: ABÂ² = BH Ã— BC vÃ  ACÂ² = CH Ã— BC
    Do Ä‘Ã³: ABÂ² + ACÂ² = BH Ã— BC + CH Ã— BC = BC Ã— (BH + CH) = BCÂ²
    
    VÃ­ dá»¥ 1: Cho tam giÃ¡c vuÃ´ng cÃ³ hai cáº¡nh gÃ³c vuÃ´ng lÃ  3 vÃ  4.
    TÃ­nh cáº¡nh huyá»n: c = âˆš(3Â² + 4Â²) = âˆš(9 + 16) = âˆš25 = 5
    
    Äá»‹nh lÃ½ 2: Äá»‹nh lÃ½ cosin
    Trong tam giÃ¡c ABC báº¥t ká»³: aÂ² = bÂ² + cÂ² - 2bcÃ—cos(A)
    """
    
    # TÃ i liá»‡u cÃ³ cáº¥u trÃºc
    structured_content = """
    ChÆ°Æ¡ng 1: Giá»›i thiá»‡u vá» Cáº¥u trÃºc Dá»¯ liá»‡u
    
    1.1 Äá»‹nh nghÄ©a
    Cáº¥u trÃºc dá»¯ liá»‡u lÃ  cÃ¡ch tá»• chá»©c vÃ  lÆ°u trá»¯ dá»¯ liá»‡u trong mÃ¡y tÃ­nh.
    
    1.2 PhÃ¢n loáº¡i
    a) Cáº¥u trÃºc tuyáº¿n tÃ­nh:
       - Máº£ng (Array)
       - Danh sÃ¡ch liÃªn káº¿t (Linked List)
       - NgÄƒn xáº¿p (Stack)
       - HÃ ng Ä‘á»£i (Queue)
    
    b) Cáº¥u trÃºc phi tuyáº¿n:
       - CÃ¢y (Tree)
       - Äá»“ thá»‹ (Graph)
    
    1.3 á»¨ng dá»¥ng
    â€¢ Tá»‘i Æ°u hÃ³a thuáº­t toÃ¡n
    â€¢ Quáº£n lÃ½ bá»™ nhá»› hiá»‡u quáº£
    â€¢ TÄƒng tá»‘c Ä‘á»™ truy xuáº¥t dá»¯ liá»‡u
    
    ChÆ°Æ¡ng 2: Máº£ng vÃ  Danh sÃ¡ch
    
    2.1 Máº£ng
    Máº£ng lÃ  táº­p há»£p cÃ¡c pháº§n tá»­ cÃ¹ng kiá»ƒu dá»¯ liá»‡u.
    Æ¯u Ä‘iá»ƒm: Truy xuáº¥t nhanh theo chá»‰ sá»‘
    NhÆ°á»£c Ä‘iá»ƒm: KÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh
    """
    
    # TÃ i liá»‡u tá»± nhiÃªn
    narrative_content = """
    Lá»‹ch sá»­ phÃ¡t triá»ƒn cá»§a mÃ¡y tÃ­nh Ä‘iá»‡n tá»­ báº¯t Ä‘áº§u tá»« nhá»¯ng nÄƒm 1940. 
    MÃ¡y tÃ­nh Ä‘áº§u tiÃªn ENIAC Ä‘Æ°á»£c xÃ¢y dá»±ng táº¡i Äáº¡i há»c Pennsylvania vÃ o nÄƒm 1946.
    NÃ³ náº·ng tá»›i 30 táº¥n vÃ  chiáº¿m diá»‡n tÃ­ch 167 mÃ©t vuÃ´ng.
    
    Trong nhá»¯ng tháº­p ká»· tiáº¿p theo, cÃ´ng nghá»‡ mÃ¡y tÃ­nh Ä‘Ã£ cÃ³ nhá»¯ng bÆ°á»›c tiáº¿n vÆ°á»£t báº­c.
    Viá»‡c phÃ¡t minh ra transistor vÃ o nÄƒm 1947 Ä‘Ã£ má»Ÿ ra ká»· nguyÃªn má»›i.
    Sau Ä‘Ã³ lÃ  sá»± ra Ä‘á»i cá»§a vi xá»­ lÃ½ vÃ o nhá»¯ng nÄƒm 1970.
    
    NgÃ y nay, mÃ¡y tÃ­nh Ä‘Ã£ trá»Ÿ thÃ nh má»™t pháº§n khÃ´ng thá»ƒ thiáº¿u trong cuá»™c sá»‘ng.
    Tá»« Ä‘iá»‡n thoáº¡i thÃ´ng minh Ä‘áº¿n siÃªu mÃ¡y tÃ­nh, chÃºng Ä‘á»u dá»±a trÃªn nhá»¯ng nguyÃªn lÃ½ cÆ¡ báº£n giá»‘ng nhau.
    TrÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  há»c mÃ¡y Ä‘ang Ä‘á»‹nh hÃ¬nh tÆ°Æ¡ng lai cá»§a cÃ´ng nghá»‡.
    """
    
    return [
        Document(page_content=math_content, metadata={"type": "mathematical", "subject": "geometry"}),
        Document(page_content=structured_content, metadata={"type": "structured", "subject": "data_structures"}),
        Document(page_content=narrative_content, metadata={"type": "narrative", "subject": "computer_history"})
    ]

def run_chunking_comparison():
    """Cháº¡y so sÃ¡nh cÃ¡c chiáº¿n lÆ°á»£c chunking"""
    
    st.title("ğŸ§  Demo Semantic Chunking")
    st.markdown("---")
    
    # Initialize components
    try:
        google_api_key = os.getenv("GOOGLE_API_KEY")
        if not google_api_key:
            st.error("Vui lÃ²ng thiáº¿t láº­p GOOGLE_API_KEY trong file .env")
            return
            
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        chunking_manager = ChunkingManager(embeddings)
        
        st.success("âœ… ÄÃ£ khá»Ÿi táº¡o thÃ nh cÃ´ng Semantic Chunking Manager")
        
    except Exception as e:
        st.error(f"Lá»—i khá»Ÿi táº¡o: {e}")
        return
    
    # Create sample documents
    sample_docs = create_sample_documents()
    
    st.markdown("## ğŸ“„ TÃ i liá»‡u máº«u")
    for i, doc in enumerate(sample_docs):
        with st.expander(f"TÃ i liá»‡u {i+1}: {doc.metadata['subject']}"):
            st.text(doc.page_content[:500] + "..." if len(doc.page_content) > 500 else doc.page_content)
    
    st.markdown("---")
    st.markdown("## ğŸ”¬ So sÃ¡nh cÃ¡c chiáº¿n lÆ°á»£c Chunking")
    
    # Get available strategies
    strategies = chunking_manager.get_available_strategies()
    
    results = {}
    
    # Test each strategy
    for strategy_name, strategy_desc in strategies.items():
        st.markdown(f"### {strategy_name.title()}")
        st.info(f"ğŸ“ {strategy_desc}")
        
        with st.spinner(f"Äang test {strategy_name}..."):
            start_time = time.time()
            
            try:
                chunks, stats = chunking_manager.process_documents(sample_docs, strategy_name)
                processing_time = time.time() - start_time
                
                results[strategy_name] = {
                    'chunks': chunks,
                    'stats': stats,
                    'processing_time': processing_time
                }
                
                # Display results
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Tá»•ng chunks", stats.get('total_chunks', 0))
                with col2:
                    st.metric("Äá»™ dÃ i TB", f"{stats.get('avg_chunk_length', 0):.0f}")
                with col3:
                    st.metric("Thá»i gian", f"{processing_time:.2f}s")
                with col4:
                    st.metric("Hiá»‡u quáº£", f"{stats.get('total_chunks', 0)/processing_time:.1f} chunks/s")
                
                # Show chunk types
                chunk_types = stats.get('chunk_types', {})
                if chunk_types:
                    st.write("ğŸ“Š **PhÃ¢n bá»‘ loáº¡i chunks:**")
                    for chunk_type, count in chunk_types.items():
                        st.write(f"â€¢ {chunk_type}: {count}")
                
                # Show sample chunks
                with st.expander("ğŸ‘€ Xem máº«u chunks"):
                    for i, chunk in enumerate(chunks[:3]):  # Show first 3 chunks
                        st.write(f"**Chunk {i+1}** ({chunk.metadata.get('chunk_type', 'unknown')}):")
                        st.text(chunk.page_content[:200] + "..." if len(chunk.page_content) > 200 else chunk.page_content)
                        st.write("---")
                
            except Exception as e:
                st.error(f"Lá»—i khi test {strategy_name}: {e}")
        
        st.markdown("---")
    
    # Summary comparison
    if results:
        st.markdown("## ğŸ“Š Tá»•ng káº¿t So sÃ¡nh")
        
        comparison_data = []
        for strategy, result in results.items():
            stats = result['stats']
            comparison_data.append({
                'Chiáº¿n lÆ°á»£c': strategy.title(),
                'Tá»•ng chunks': stats.get('total_chunks', 0),
                'Äá»™ dÃ i TB': f"{stats.get('avg_chunk_length', 0):.0f}",
                'Thá»i gian (s)': f"{result['processing_time']:.2f}",
                'Hiá»‡u quáº£': f"{stats.get('total_chunks', 0)/result['processing_time']:.1f}"
            })
        
        st.dataframe(comparison_data)
        
        # Recommendations
        st.markdown("## ğŸ’¡ Khuyáº¿n nghá»‹")
        
        best_adaptive = max(results.items(), key=lambda x: x[1]['stats'].get('total_chunks', 0) if x[0] == 'adaptive' else 0)
        fastest = min(results.items(), key=lambda x: x[1]['processing_time'])
        most_chunks = max(results.items(), key=lambda x: x[1]['stats'].get('total_chunks', 0))
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.success(f"ğŸ¯ **Tá»‘t nháº¥t tá»•ng thá»ƒ**: {best_adaptive[0].title()}")
        with col2:
            st.info(f"âš¡ **Nhanh nháº¥t**: {fastest[0].title()}")
        with col3:
            st.warning(f"ğŸ“ˆ **Nhiá»u chunks nháº¥t**: {most_chunks[0].title()}")

if __name__ == "__main__":
    run_chunking_comparison()
